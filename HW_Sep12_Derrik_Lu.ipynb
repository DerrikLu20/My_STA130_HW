{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb4b07d",
   "metadata": {},
   "source": [
    "                                   STA130 Homework 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9aec0f",
   "metadata": {},
   "source": [
    "Homework GPT Links:\n",
    "- Problem 1: https://chatgpt.com/share/66edcbfa-a3d0-800e-ac98-19d9467f7116\n",
    "- Problem 2-5: https://chatgpt.com/share/66ef949d-60f0-800e-bf0e-53ffc263dd32 \n",
    "- Problem 6-8: https://chatgpt.com/share/66ef9a2f-4264-800e-8d4f-367194dd719e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddaa4d2",
   "metadata": {},
   "source": [
    "#### Problem 1: Pick one of the datasets from the ChatBot session(s) of the TUT demo (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d36044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Species  Age (years)  Weight (kg)   Habitat       Diet\n",
      "0      Lion          5.0        190.0  Savannah  Carnivore\n",
      "1  Elephant         12.0       5400.0    Forest  Herbivore\n",
      "2   Cheetah          NaN         50.0  Savannah  Carnivore\n",
      "3     Zebra          7.0          NaN  Savannah  Herbivore\n",
      "4   Giraffe         15.0        900.0  Savannah  Herbivore\n",
      "5   Gorilla         10.0        160.0    Forest   Omnivore\n",
      "6    Parrot          2.0          1.5    Jungle  Herbivore\n",
      "7    Python          NaN         80.0    Jungle  Carnivore\n",
      "\n",
      "Missing values per column:\n",
      "Species        0\n",
      "Age (years)    2\n",
      "Weight (kg)    1\n",
      "Habitat        0\n",
      "Diet           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the dataset as a dictionary\n",
    "data = {\n",
    "    'Species': ['Lion', 'Elephant', 'Cheetah', 'Zebra', 'Giraffe', 'Gorilla', 'Parrot', 'Python'],\n",
    "    'Age (years)': [5, 12, np.nan, 7, 15, 10, 2, np.nan],\n",
    "    'Weight (kg)': [190, 5400, 50, np.nan, 900, 160, 1.5, 80],\n",
    "    'Habitat': ['Savannah', 'Forest', 'Savannah', 'Savannah', 'Savannah', 'Forest', 'Jungle', 'Jungle'],\n",
    "    'Diet': ['Carnivore', 'Herbivore', 'Carnivore', 'Herbivore', 'Herbivore', 'Omnivore', 'Herbivore', 'Carnivore']\n",
    "}\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display the dataset and the missing values count\n",
    "print(df)\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e712a",
   "metadata": {},
   "source": [
    "#### Problem 2: Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to determine how many columns and rows of data a pandas DataFrame has, and then use code provided in your ChatBot session to print out the number of rows and columns of the dataset; and, write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c61535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 344\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\"\n",
    "penguins = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the DataFrame\n",
    "rows, columns = penguins.shape\n",
    "print(f'Number of rows: {rows}')\n",
    "print(f'Number of columns: {columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5528d",
   "metadata": {},
   "source": [
    "- Observations: An observation is a single record or instance of data\n",
    "- Variables: Attributes or features that describe each observation like flipper length for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42042f1",
   "metadata": {},
   "source": [
    "#### Problem 3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51a9dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of numerical columns:\n",
      "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
      "count      342.000000     342.000000         342.000000   342.000000\n",
      "mean        43.921930      17.151170         200.915205  4201.754386\n",
      "std          5.459584       1.974793          14.061714   801.954536\n",
      "min         32.100000      13.100000         172.000000  2700.000000\n",
      "25%         39.225000      15.600000         190.000000  3550.000000\n",
      "50%         44.450000      17.300000         197.000000  4050.000000\n",
      "75%         48.500000      18.700000         213.000000  4750.000000\n",
      "max         59.600000      21.500000         231.000000  6300.000000\n",
      "\n",
      "Info about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Summary of numerical columns\n",
    "numerical_summary = penguins.describe()\n",
    "print(\"Summary of numerical columns:\")\n",
    "print(numerical_summary)\n",
    "\n",
    "# Summary of all columns\n",
    "print(\"\\nInfo about the dataset:\")\n",
    "penguins.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064289cb",
   "metadata": {},
   "source": [
    "#### Problem 4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by df.shape and what is reported by df.describe() with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953a2c9",
   "metadata": {},
   "source": [
    "- df.shape includes all columns, while df.describe() only includes numeric ones, leading to fewer columns in the summary\n",
    "- The \"count\" in df.describe() reflects only non-null entries in numeric columns, which may be less than the total row count due to missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be194d",
   "metadata": {},
   "source": [
    "#### Problem 5: Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91018c3",
   "metadata": {},
   "source": [
    "- an \"attribute\", such as df.shape which does not end with ()\n",
    "- and a \"method\", such as df.describe() which does end with ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cfaaae",
   "metadata": {},
   "source": [
    "Chatbot:\n",
    "1. An attribute is a property or characteristic of an object that stores information. Attributes are accessed directly without parentheses.\n",
    "2. A method is a function that is associated with an object. Methods perform actions or computations and are called using parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08225887",
   "metadata": {},
   "source": [
    "Paraphrase:\n",
    "1. An attribute is like a description of the object such as height for a person or the state of a liquid (liquid or solid).\n",
    "2. A method is more like an action that the object can perform such as walking for a human."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94802e",
   "metadata": {},
   "source": [
    "#### Problem 6: The df.describe() method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a7c317",
   "metadata": {},
   "source": [
    "1. Count: The number of non-null entries for each column. This helps to understand how many data points are available for analysis.\n",
    "\n",
    "2. Mean: The average of the values in a column. Itâ€™s calculated by summing all the values and dividing by the count of those values.\n",
    "\n",
    "3. Std (Standard Deviation): A measure of the amount of variation or dispersion in a set of values. A low standard deviation means the values tend to be close to the mean, while a high standard deviation indicates that the values are spread out over a wider range.\n",
    "\n",
    "4. Min: The smallest value in the dataset. This helps to identify the lower boundary of the data.\n",
    "\n",
    "5. 25% (First Quartile): The value below which 25% of the data falls. This is also known as the first quartile (Q1) and indicates the lower quarter of the data distribution.\n",
    "\n",
    "6. 50% (Median or Second Quartile): The middle value of the dataset when it is ordered. Half of the data points are below this value, and half are above it.\n",
    "\n",
    "7. 75% (Third Quartile): The value below which 75% of the data falls. This is also known as the third quartile (Q3) and represents the upper quarter of the data distribution.\n",
    "\n",
    "8. Max: The largest value in the dataset. This indicates the upper boundary of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f4472",
   "metadata": {},
   "source": [
    "#### Problem 7: Missing data can be considered \"across rows\" or \"down columns\". Consider how df.dropna() or del df['col'] should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3913fa2",
   "metadata": {},
   "source": [
    "ChatBot:\n",
    "\n",
    "1. df.dropna():\n",
    "\n",
    "This method is used to remove missing values (NaN) from a DataFrame.\n",
    "By default, it drops any rows that contain at least one NaN value, but you can customize its behavior with parameters like axis (to drop columns instead) and how (to drop rows/columns based on all or any NaN values).\n",
    "For example, df.dropna(axis=0) will drop rows, while df.dropna(axis=1) will drop columns with any NaN values.\n",
    "\n",
    "2. del df['col']:\n",
    "\n",
    "This statement is used to delete a specific column from the DataFrame.\n",
    "After executing del df['col'], the specified column will be permanently removed from the DataFrame.\n",
    "Note that this action cannot be undone, so it's important to be certain before deleting a column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eadae1",
   "metadata": {},
   "source": [
    "Questions: \n",
    "\n",
    "- Provide an example of a \"use case\" in which using df.dropna() might be peferred over using del df['col']\n",
    "\n",
    "\n",
    "- Provide an example of \"the opposite use case\" in which using del df['col'] might be preferred over using df.dropna()\n",
    "\n",
    "\n",
    "- Discuss why applying del df['col'] before df.dropna() when both are used together could be important\n",
    "\n",
    "\n",
    "- Remove all missing data from one of the datasets you're considering using some combination of del df['col'] and/or df.dropna() and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b38ddc7",
   "metadata": {},
   "source": [
    "1. df.dropna() might be more useful than del df['col'] when you are trying to look for specific missing values to remove, as del df['col'] will get rid of the entire specific column from the dataframe.\n",
    "2. Instead of dropping just rows, I may need to drop an entire column if for example I am missing too many data values in a column and want to drop it instead. \n",
    "3. If a column has alot missing data, removing it before using dropna() can reduce the number of rows I need to get rid of later.\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce5e2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Before Cleaning:\n",
      "bill_length_mm        2\n",
      "bill_depth_mm         2\n",
      "flipper_length_mm     2\n",
      "body_mass_g           2\n",
      "sex                  11\n",
      "dtype: int64\n",
      "\n",
      "Missing Values After Cleaning:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Cleaned DataFrame:\n",
      "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
      "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
      "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
      "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
      "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
      "\n",
      "   body_mass_g     sex  \n",
      "0       3750.0    MALE  \n",
      "1       3800.0  FEMALE  \n",
      "2       3250.0  FEMALE  \n",
      "4       3450.0  FEMALE  \n",
      "5       3650.0    MALE  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the penguins dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\"\n",
    "df_penguins = pd.read_csv(url)\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "missing_values = df_penguins.isnull().sum()\n",
    "print(\"Missing Values Before Cleaning:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Remove all rows with missing data\n",
    "df_penguins_cleaned = df_penguins.dropna()\n",
    "\n",
    "# Check for missing values after cleaning\n",
    "missing_values_after = df_penguins_cleaned.isnull().sum()\n",
    "print(\"\\nMissing Values After Cleaning:\")\n",
    "print(missing_values_after[missing_values_after > 0])\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(df_penguins_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301d3be",
   "metadata": {},
   "source": [
    "Before: \n",
    "\n",
    "- Missing Values Before Cleaning:\n",
    "- species        7\n",
    "- island         2\n",
    "- bill_length_mm  1\n",
    "- bill_depth_mm   1\n",
    "- flipper_length_mm  0\n",
    "- body_mass_g     0\n",
    "- sex             7\n",
    "- dtype: int64\n",
    "\n",
    "After: \n",
    "\n",
    "- Total rows before cleaning: 344\n",
    "- Total rows after cleaning: 333\n",
    "\n",
    "Missing Values After Cleaning:\n",
    "- Series([], dtype: int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abc455",
   "metadata": {},
   "source": [
    "#### Problem 8. Give brief explanations in your own words for any requested answers to the questions below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdfeb88",
   "metadata": {},
   "source": [
    "1. Use your ChatBot session to understand what df.groupby(\"col1\")[\"col2\"].describe() does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you\n",
    "<br> \n",
    "2. Assuming you've not yet removed missing values in the manner of question \"7\" above, df.describe() would have different values in the count value for different data columns depending on the missingness present in the original data. Why do these capture something fundamentally different from the values in the count that result from doing something like df.groupby(\"col1\")[\"col2\"].describe()?\n",
    "<br> \n",
    "3. Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT\n",
    "\n",
    "    1. Forget to include import pandas as pd in your code\n",
    "        Use Kernel->Restart from the notebook menu to restart the jupyter notebook session unload imported libraries and start over so you can create this error\n",
    "\n",
    "    2. When python has an error, it sometimes provides a lot of \"stack trace\" output, but that's not usually very important for troubleshooting. For this problem for example, all you need to share with ChatGPT or search on google is \"NameError: name 'pd' is not defined\"\n",
    "\n",
    "\n",
    "    3. Mistype \"titanic.csv\" as \"titanics.csv\" If ChatBot troubleshooting is based on downloading the file, just replace the whole url with \"titanics.csv\" and try to troubleshoot the subsequent FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv' (assuming the file is indeed not present)\n",
    "\n",
    "    4. Explore introducing typos into a couple other parts of the url and note the slightly different errors this produces\n",
    "\n",
    "\n",
    "    5. Try to use a dataframe before it's been assigned into the variable You can simulate this by just misnaming the variable. For example, if you should write df.groupby(\"col1\")[\"col2\"].describe() based on how you loaded the data, then instead write DF.groupby(\"col1\")[\"col2\"].describe()\n",
    "\n",
    "    6. Make sure you've fixed your file name so that's not the error any more\n",
    "\n",
    "\n",
    "    7. Forget one of the parentheses somewhere the code. For example, if the code should be pd.read_csv(url) the change it to pd.read_csv(url\n",
    "\n",
    "\n",
    "    8. Mistype one of the names of the chained functions with the code. For example, try something like df.group_by(\"col1\")[\"col2\"].describe() and df.groupby(\"col1\")[\"col2\"].describle()\n",
    "\n",
    "\n",
    "    9. Use a column name that's not in your data for the groupby and column selection For example, try capitalizing the columns for example replacing \"sex\" with \"Sex\" in titanic_df.groupby(\"sex\")[\"age\"].describe(), and then instead introducing the same error of \"age\"\n",
    "\n",
    "\n",
    "    10. Forget to put the column name as a string in quotes for the groupby and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question. For example, something like titanic_df.groupby(sex)[\"age\"].describe(), and then titanic_df.groupby(\"sex\")[age].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aba9fa",
   "metadata": {},
   "source": [
    "1. The method df.groupby(\"col1\")[\"col2\"].describe() provides a summary of statistics for the col2 column, grouped by the unique values in col1. This means that it calculates statistics such as count, mean, standard deviation, min, max, and quartiles for col2, separately for each unique value in col1.\n",
    "\n",
    "2. When you run df.describe() on the entire DataFrame, the count reflects the total number of non-missing entries for each column across the entire dataset. If a column has missing values, this count will be lower than the total number of rows in the dataset.\n",
    "\n",
    "3. Generally speaking, using the ChatBot is much more efficient in recognizing my own faults in code compared to Google. However, this is assuming that my code is easy enough for the ChatBot to understand and fix in the first place. When it comes to longer code or more complicated coding, websites such as Stack Overflow and google may be of more use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76482a4f",
   "metadata": {},
   "source": [
    "#### 9. Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea01ed",
   "metadata": {},
   "source": [
    "Yes I have done so through ChatBot. I have missed the first lecture and tutorial unfortunately, so the ChatBots helped me understand the missing information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
